import { APIResource } from "../core/resource.mjs";
import { APIPromise } from "../core/api-promise.mjs";
import { RequestOptions } from "../internal/request-options.mjs";
export declare class SpeechToText extends APIResource {
    /**
     * Transcribe audio streams to text over WebSocket.
     */
    transcribe(query: SpeechToTextTranscribeParams, options?: RequestOptions): APIPromise<void>;
}
export interface SpeechToTextTranscribeParams {
    /**
     * The format of input audio stream.
     */
    input_format: 'mp3' | 'wav';
    /**
     * The transcription engine to use for processing the audio stream.
     */
    transcription_engine: 'Azure' | 'Deepgram' | 'Google' | 'Telnyx';
    /**
     * Whether to receive interim transcription results.
     */
    interim_results?: boolean;
    /**
     * The language spoken in the audio stream.
     */
    language?: string;
    /**
     * The specific model to use within the selected transcription engine.
     */
    model?: 'fast' | 'deepgram/nova-2' | 'deepgram/nova-3' | 'latest_long' | 'latest_short' | 'command_and_search' | 'phone_call' | 'video' | 'default' | 'medical_conversation' | 'medical_dictation' | 'openai/whisper-tiny' | 'openai/whisper-large-v3-turbo';
}
export declare namespace SpeechToText {
    export { type SpeechToTextTranscribeParams as SpeechToTextTranscribeParams };
}
//# sourceMappingURL=speech-to-text.d.mts.map